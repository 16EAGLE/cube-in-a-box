version: '3'

services:
  postgres:
    image: postgres:10.3
    environment:
      - POSTGRES_DB=opendatacube
      - POSTGRES_PASSWORD=opendatacubepassword
      - POSTGRES_USER=opendatacube
    restart: always

  dask-scheduler:
    build:
      context: dask
    environment:
      - POSTGRES_DB=opendatacube
      - POSTGRES_PASSWORD=opendatacubepassword
      - POSTGRES_USER=opendatacube
      - AWS_ACCESS_KEY_ID=${ODC_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${ODC_SECRET_KEY}
    ports:
      - "8786:8786"
      - "8787:8787"
    command: ["dask-scheduler"]

  dask-worker:
    build:
      context: dask
    environment:
      - POSTGRES_DB=opendatacube
      - POSTGRES_PASSWORD=opendatacubepassword
      - POSTGRES_USER=opendatacube
      - AWS_ACCESS_KEY_ID=${ODC_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${ODC_SECRET_KEY}
    command: ["dask-worker", "--nprocs", "1", "--nthreads", "1", "tcp://dask-scheduler:8786"]
  
  jupyter:
    build: .
    environment:
      - DB_HOSTNAME=postgres
      - DB_USERNAME=opendatacube
      - DB_PASSWORD=opendatacubepassword
      - DB_DATABASE=opendatacube
      - AWS_ACCESS_KEY_ID=${ODC_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${ODC_SECRET_KEY}
    ports:
      - "8888:8888"
      - "7777:8786"
      - "6666:8787"
    volumes:
      - ./scripts:/opt/odc/scripts
      - ./data:/opt/odc/data
      - ./notebooks:/notebooks
    restart: always
    shm_size: 1g
    command: jupyter notebook --allow-root --ip="0.0.0.0" --NotebookApp.token='secretpassword'
